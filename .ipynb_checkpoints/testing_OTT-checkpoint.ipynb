{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5c9064bb-0d5f-462a-9a99-5a9191692d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import pickle\n",
    "from tqdm.auto import trange, tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "from datasets import load_from_disk\n",
    "from omegaconf import OmegaConf\n",
    "from replay_buffer import ReplayBuffer\n",
    "\n",
    "from citylearn.agents.rbc import HourRBC\n",
    "from citylearn.agents.q_learning import TabularQLearning\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from citylearn.data import DataSet\n",
    "from citylearn.reward_function import RewardFunction\n",
    "from citylearn.wrappers import NormalizedObservationWrapper\n",
    "from citylearn.wrappers import StableBaselines3Wrapper\n",
    "from citylearn.wrappers import TabularQLearningWrapper\n",
    "\n",
    "from stable_baselines3.a2c import A2C\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from trajectory.models.gpt import GPT, GPTTrainer\n",
    "\n",
    "from trajectory.utils.common import pad_along_axis\n",
    "from trajectory.utils.discretization import KBinsDiscretizer\n",
    "from trajectory.utils.env import create_env\n",
    "import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "49838ec3-4e1b-4eb1-95a1-92a7514d066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_trajectory(trajectories):\n",
    "    states, traj_lens, returns = [], [], []\n",
    "    for i in trajectories:\n",
    "        states.append(trajectories[i][\"states\"])\n",
    "        traj_lens.append(len(trajectories[i][\"states\"]))\n",
    "        returns.append(np.array(trajectories[i][\"rewards\"]).sum())\n",
    "    num_timesteps = sum(traj_lens)\n",
    "    sorted_inds = np.argsort(returns)  # lowest to highest\n",
    "    num_trajectories = 1\n",
    "    timesteps = traj_lens[sorted_inds[-1]]\n",
    "    ind = len(trajectories) - 2\n",
    "    while ind >= 0 and timesteps + traj_lens[sorted_inds[ind]] < num_timesteps:\n",
    "        timesteps += traj_lens[sorted_inds[ind]]\n",
    "        num_trajectories += 1\n",
    "        ind -= 1\n",
    "    sorted_inds = sorted_inds[-num_trajectories:]\n",
    "    print(sorted_inds)\n",
    "            #print(trajectories[1])\n",
    "    for ii in sorted_inds:\n",
    "        print(ii)\n",
    "            #print(trajectories[0].keys())\n",
    "    trajectories = [trajectories[int(ii)] for ii in sorted_inds]\n",
    "    for trajectory in trajectories:\n",
    "        for key in trajectory.keys():\n",
    "            trajectory[key] = np.array(trajectory[key])\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "da70d576-f65b-4a58-b129-e7de00fd1ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_trajectory(states, actions, rewards, discount=0.99):\n",
    "    traj_length = states.shape[0]\n",
    "    # I can vectorize this for all dataset as once,\n",
    "    # but better to be safe and do it once and slow and right (and cache it)\n",
    "    \n",
    "    if actions.ndim == 3 :\n",
    "        actions = actions.reshape(actions.shape[0],actions.shape[1])\n",
    "    \n",
    "    if rewards.ndim == 1 :\n",
    "        rewards = rewards.reshape(rewards.shape[0],1)\n",
    "        \n",
    "    print(\"Discount \"+str(discount))\n",
    "    discounts = (discount ** np.arange(traj_length))\n",
    "\n",
    "    values = np.zeros_like(rewards)\n",
    "    for t in range(traj_length):\n",
    "        # discounted return-to-go from state s_t:\n",
    "        # r_{t+1} + y * r_{t+2} + y^2 * r_{t+3} + ...\n",
    "        # .T as rewards of shape [len, 1], see https://github.com/Howuhh/faster-trajectory-transformer/issues/9\n",
    "        values[t] = (rewards[t + 1:].T * discounts[:-t - 1]).sum()\n",
    "    print(states.shape)\n",
    "    print(actions.shape)\n",
    "    print(rewards.shape)\n",
    "    print(values.shape)\n",
    "\n",
    "    joined_transition = np.concatenate([states, actions, rewards, values], axis=-1)\n",
    "\n",
    "    return joined_transition\n",
    "\n",
    "def segment(states, actions, rewards, terminals):\n",
    "    assert len(states) == len(terminals)\n",
    "    \n",
    "    trajectories = {}\n",
    "\n",
    "    episode_num = 0\n",
    "    for t in trange(len(terminals), desc=\"Segmenting\"):\n",
    "        if episode_num not in trajectories:\n",
    "            trajectories[episode_num] = {\n",
    "                \"states\": [],\n",
    "                \"actions\": [],\n",
    "                \"rewards\": []\n",
    "            }\n",
    "        \n",
    "        trajectories[episode_num][\"states\"].append(states[t])\n",
    "        trajectories[episode_num][\"actions\"].append(actions[t])\n",
    "        trajectories[episode_num][\"rewards\"].append(rewards[t])\n",
    "\n",
    "        if terminals[t]:\n",
    "            # next episode\n",
    "            episode_num = episode_num + 1\n",
    "\n",
    "    trajectories_lens = [len(v[\"states\"]) for k, v in trajectories.items()]\n",
    "\n",
    "    for t in trajectories:\n",
    "        trajectories[t][\"states\"] = np.stack(trajectories[t][\"states\"], axis=0)\n",
    "        trajectories[t][\"actions\"] = np.stack(trajectories[t][\"actions\"], axis=0)\n",
    "        trajectories[t][\"rewards\"] = np.stack(trajectories[t][\"rewards\"], axis=0)\n",
    "\n",
    "    return trajectories, trajectories_lens\n",
    "\n",
    "class DiscretizedDataset(Dataset):\n",
    "    def __init__(self, trajectories,traj_lengths, env_name=\"city_learn\", num_bins=100, seq_len=10, discount=0.99, strategy=\"uniform\", cache_path=\"data\"):\n",
    "        self.seq_len = seq_len\n",
    "        self.discount = discount\n",
    "        self.num_bins = num_bins\n",
    "        self.dataset = dataset\n",
    "        self.env_name = env_name\n",
    "        \n",
    "        #trajectories, traj_lengths = segment(self.dataset[\"observations\"],self.dataset[\"actions\"],self.dataset[\"rewards\"],self.dataset[\"dones\"])\n",
    "        #trajectories = self.sort_trajectory(trajectories)\n",
    "        self.trajectories = trajectories\n",
    "        self.traj_lengths = traj_lengths\n",
    "        self.cache_path = cache_path\n",
    "        self.cache_name = f\"{env_name}_{num_bins}_{seq_len}_{strategy}_{discount}\"\n",
    "        \n",
    "        self.joined_transitions = []\n",
    "        for i,t in enumerate(tqdm(trajectories, desc=\"Joining transitions\")):\n",
    "            self.joined_transitions.append(\n",
    "                    join_trajectory(trajectories[i][\"states\"], trajectories[i][\"actions\"], trajectories[i][\"rewards\"],discount = self.discount)\n",
    "                )\n",
    "        \"\"\"\n",
    "        if cache_path is None or not os.path.exists(os.path.join(cache_path, self.cache_name)):\n",
    "            self.joined_transitions = []\n",
    "            for t in tqdm(trajectories, desc=\"Joining transitions\"):\n",
    "                self.joined_transitions.append(\n",
    "                    join_trajectory(trajectories[t][\"states\"], trajectories[t][\"actions\"], trajectories[t][\"rewards\"],discount = self.discount)\n",
    "                )\n",
    "\n",
    "            os.makedirs(os.path.join(cache_path), exist_ok=True)\n",
    "            # save cached version\n",
    "            with open(os.path.join(cache_path, self.cache_name), \"wb\") as f:\n",
    "                pickle.dump(self.joined_transitions, f)\n",
    "        else:\n",
    "            with open(os.path.join(cache_path, self.cache_name), \"rb\") as f:\n",
    "                self.joined_transitions = pickle.load(f)\n",
    "        \"\"\"\n",
    "\n",
    "        self.discretizer = KBinsDiscretizer(\n",
    "            np.concatenate(self.joined_transitions, axis=0),\n",
    "            num_bins=num_bins,\n",
    "            strategy=strategy\n",
    "        )\n",
    "\n",
    "        # get valid indices for seq_len sampling\n",
    "        indices = []\n",
    "        for path_ind, length in enumerate(traj_lengths):\n",
    "            end = length - 1\n",
    "            for i in range(end):\n",
    "                indices.append((path_ind, i, i + self.seq_len))\n",
    "        self.indices = np.array(indices)\n",
    "\n",
    "    def get_env_name(self):\n",
    "        return self.env.name\n",
    "\n",
    "   \n",
    "\n",
    "    def get_discretizer(self):\n",
    "        return self.discretizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx)\n",
    "        traj_idx, start_idx, end_idx = self.indices[idx]\n",
    "        \n",
    "        joined = self.joined_transitions[traj_idx][start_idx:end_idx]\n",
    "        \n",
    "\n",
    "        loss_pad_mask = np.ones((self.seq_len, joined.shape[-1]))\n",
    "        if joined.shape[0] < self.seq_len:\n",
    "            # pad to seq_len if at the end of trajectory, mask for padding\n",
    "            loss_pad_mask[joined.shape[0]:] = 0\n",
    "            joined = pad_along_axis(joined, pad_to=self.seq_len, axis=0)\n",
    "\n",
    "        joined_discrete = self.discretizer.encode(joined).reshape(-1).astype(np.longlong)\n",
    "        loss_pad_mask = loss_pad_mask.reshape(-1)\n",
    "\n",
    "        return joined_discrete[:-1], joined_discrete[1:], loss_pad_mask[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "be94b5a7-68d6-4c74-b886-fba42a1d9a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "aa45051a-4654-42bd-a18b-80b556402a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config_path = \"configs/medium/city_learn_traj.yaml\",offline_data_path = None,device = \"cpu\"):\n",
    "    config = OmegaConf.load(config_path)\n",
    "\n",
    "    if offline_data_path is None :\n",
    "        offline_data_path = config.trainer.offline_data_path\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:1\"\n",
    "\n",
    "  \n",
    "    wandb.init(\n",
    "            **config.wandb,\n",
    "            config=dict(OmegaConf.to_container(config, resolve=True))\n",
    "        )\n",
    "    \n",
    "    offline_data_path = offline_data_path\n",
    "    dataset = load_from_disk(offline_data_path)\n",
    "\n",
    "    trajectories, traj_lengths = segment(dataset[\"observations\"],dataset[\"actions\"],dataset[\"rewards\"],dataset[\"dones\"])\n",
    "    offline_trajectories = sort_trajectory(trajectories)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(5, offline_trajectories)\n",
    "\n",
    "\n",
    "    datasets = DiscretizedDataset(offline_trajectories,traj_lengths,discount = config.dataset.discount, seq_len = config.dataset.seq_len, strategy = config.dataset.strategy)\n",
    "    dataloader = DataLoader(datasets,  batch_size=config.dataset.batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "    trainer_conf = config.trainer\n",
    "    data_conf = config.dataset\n",
    "\n",
    "    model = GPT(**config.model)\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "    num_epochs = config.trainer.num_epochs\n",
    "\n",
    "    warmup_tokens = len(datasets) * data_conf.seq_len * config.model.transition_dim\n",
    "    final_tokens = warmup_tokens * num_epochs\n",
    "\n",
    "    trainer = GPTTrainer(\n",
    "            final_tokens=final_tokens,\n",
    "            warmup_tokens=warmup_tokens,\n",
    "            action_weight=trainer_conf.action_weight,\n",
    "            value_weight=trainer_conf.value_weight,\n",
    "            reward_weight=trainer_conf.reward_weight,\n",
    "            learning_rate=trainer_conf.lr,\n",
    "            betas=trainer_conf.betas,\n",
    "            weight_decay=trainer_conf.weight_decay,\n",
    "            clip_grad=trainer_conf.clip_grad,\n",
    "            eval_seed=trainer_conf.eval_seed,\n",
    "            eval_every=trainer_conf.eval_every,\n",
    "            eval_episodes=trainer_conf.eval_episodes,\n",
    "            eval_temperature=trainer_conf.eval_temperature,\n",
    "            eval_discount=trainer_conf.eval_discount,\n",
    "            eval_plan_every=trainer_conf.eval_plan_every,\n",
    "            eval_beam_width=trainer_conf.eval_beam_width,\n",
    "            eval_beam_steps=trainer_conf.eval_beam_steps,\n",
    "            eval_beam_context=trainer_conf.eval_beam_context,\n",
    "            eval_sample_expand=trainer_conf.eval_sample_expand,\n",
    "            eval_k_obs=trainer_conf.eval_k_obs,  # as in original implementation\n",
    "            eval_k_reward=trainer_conf.eval_k_reward,\n",
    "            eval_k_act=trainer_conf.eval_k_act,\n",
    "            checkpoints_path=trainer_conf.checkpoints_path,\n",
    "            save_every=1,\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "    trainer.train(\n",
    "        model=model,\n",
    "        dataloader=dataloader,\n",
    "        num_epochs=num_epochs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f54b2163-cbd6-43ee-b8c8-833881783e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x115259310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danieljonatan/miniconda3/envs/stable3/lib/python3.9/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/danieljonatan/miniconda3/envs/stable3/lib/python3.9/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7d0284e28f4d04830bda2241e54b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Segmenting:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955055436ce84986a702597df6aebebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining transitions:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discount 0.99\n",
      "(8759, 44)\n",
      "(8759, 5)\n",
      "(8759, 1)\n",
      "(8759, 1)\n",
      "Discount 0.99\n",
      "(8759, 44)\n",
      "(8759, 5)\n",
      "(8759, 1)\n",
      "(8759, 1)\n",
      "Discount 0.99\n",
      "(3723, 44)\n",
      "(3723, 5)\n",
      "(3723, 1)\n",
      "(3723, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f086d7f08cb4491a7bdd089be522684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/danieljonatan/miniconda3/envs/stable3/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/danieljonatan/miniconda3/envs/stable3/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'DiscretizedDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigs/medium/city_learn_ott.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[148], line 67\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config_path, offline_data_path, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m final_tokens \u001b[38;5;241m=\u001b[39m warmup_tokens \u001b[38;5;241m*\u001b[39m num_epochs\n\u001b[1;32m     39\u001b[0m trainer \u001b[38;5;241m=\u001b[39m GPTTrainer(\n\u001b[1;32m     40\u001b[0m         final_tokens\u001b[38;5;241m=\u001b[39mfinal_tokens,\n\u001b[1;32m     41\u001b[0m         warmup_tokens\u001b[38;5;241m=\u001b[39mwarmup_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     65\u001b[0m     )\n\u001b[0;32m---> 67\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master_thesis_code/online-trajectory/trajectory/models/gpt/gpt_trainer.py:168\u001b[0m, in \u001b[0;36mGPTTrainer.train\u001b[0;34m(self, model, dataloader, num_epochs, log_every)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    167\u001b[0m     epoch_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m):\n\u001b[1;32m    169\u001b[0m         batch \u001b[38;5;241m=\u001b[39m [b\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m    170\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_loss(model, batch)\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/site-packages/tqdm/notebook.py:223\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m colour \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    222\u001b[0m display_here \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_notebook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgui\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__: \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/site-packages/tqdm/asyncio.py:33\u001b[0m, in \u001b[0;36mtqdm_asyncio.__init__\u001b[0;34m(self, iterable, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterable_next \u001b[38;5;241m=\u001b[39m iterable\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterable_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterable_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterable_iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stable3/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(config_path = \"configs/medium/city_learn_ott.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dfd97d-741a-4467-8f67-bdb5fd5c7160",
   "metadata": {},
   "source": [
    "## Online Tuning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66bf08-5e80-4b2c-b057-3f0fe4db12b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
